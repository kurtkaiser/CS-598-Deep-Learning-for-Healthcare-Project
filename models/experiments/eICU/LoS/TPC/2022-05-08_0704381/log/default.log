2022-05-08 07:04:38,780 - INFO - Config:
2022-05-08 07:04:38,781 - INFO - {
    "L2_regularisation": 0,
    "alpha": 100,
    "base_dir": "models/experiments/eICU/LoS/TPC",
    "batch_size": 32,
    "batch_size_test": 32,
    "batchnorm": "mybatchnorm",
    "dataset": "eICU",
    "diagnosis_size": 64,
    "disable_cuda": false,
    "exp_name": "TPC",
    "intermediate_reporting": false,
    "kernel_size": 4,
    "labs_only": false,
    "last_linear_size": 17,
    "learning_rate": 0.00226,
    "loss": "msle",
    "main_dropout_rate": 0.45,
    "mode": "train",
    "model_type": "tpc",
    "n_epochs": 4,
    "n_layers": 9,
    "name": "TPC",
    "no_diag": false,
    "no_exp": false,
    "no_labs": false,
    "no_mask": false,
    "no_skip_connections": false,
    "no_temp_kernels": 12,
    "percentage_data": 100.0,
    "point_size": 13,
    "point_sizes": [
        13,
        13,
        13,
        13,
        13,
        13,
        13,
        13,
        13
    ],
    "save_results_csv": false,
    "seed": 1297655619,
    "share_weights": false,
    "shuffle_train": false,
    "sum_losses": true,
    "task": "LoS",
    "temp_dropout_rate": 0.05,
    "temp_kernels": [
        12,
        12,
        12,
        12,
        12,
        12,
        12,
        12,
        12
    ]
}
2022-05-08 07:04:43,837 - INFO - Experiment set up.
2022-05-08 07:04:43,873 - INFO - TempPointConv(
  (relu): ReLU()
  (sigmoid): Sigmoid()
  (hardtanh): Hardtanh(min_val=0.020833333333333332, max_val=100)
  (msle_loss): MSLELoss(
    (squared_error): MSELoss()
  )
  (mse_loss): MSELoss(
    (squared_error): MSELoss()
  )
  (bce_loss): BCELoss()
  (main_dropout): Dropout(p=0.45, inplace=False)
  (temp_dropout): Dropout(p=0.05, inplace=False)
  (empty_module): EmptyModule()
  (diagnosis_encoder): Linear(in_features=293, out_features=64, bias=True)
  (bn_diagnosis_encoder): MyBatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (bn_point_last_los): MyBatchNorm1d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (bn_point_last_mort): MyBatchNorm1d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (point_final_los): Linear(in_features=17, out_features=1, bias=True)
  (point_final_mort): Linear(in_features=17, out_features=1, bias=True)
  (layer_modules): ModuleDict(
    (0): ModuleDict(
      (temp): Conv1d(174, 1044, kernel_size=(4,), stride=(1,), groups=87)
      (bn_temp): MyBatchNorm1d(1044, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=241, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ModuleDict(
      (temp): Conv1d(1300, 1200, kernel_size=(4,), stride=(1,), dilation=(3,), groups=100)
      (bn_temp): MyBatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1298, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ModuleDict(
      (temp): Conv1d(1469, 1356, kernel_size=(4,), stride=(1,), dilation=(6,), groups=113)
      (bn_temp): MyBatchNorm1d(1356, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1454, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): ModuleDict(
      (temp): Conv1d(1638, 1512, kernel_size=(4,), stride=(1,), dilation=(9,), groups=126)
      (bn_temp): MyBatchNorm1d(1512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1610, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): ModuleDict(
      (temp): Conv1d(1807, 1668, kernel_size=(4,), stride=(1,), dilation=(12,), groups=139)
      (bn_temp): MyBatchNorm1d(1668, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1766, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): ModuleDict(
      (temp): Conv1d(1976, 1824, kernel_size=(4,), stride=(1,), dilation=(15,), groups=152)
      (bn_temp): MyBatchNorm1d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1922, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): ModuleDict(
      (temp): Conv1d(2145, 1980, kernel_size=(4,), stride=(1,), dilation=(18,), groups=165)
      (bn_temp): MyBatchNorm1d(1980, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=2078, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): ModuleDict(
      (temp): Conv1d(2314, 2136, kernel_size=(4,), stride=(1,), dilation=(21,), groups=178)
      (bn_temp): MyBatchNorm1d(2136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=2234, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): ModuleDict(
      (temp): Conv1d(2483, 2292, kernel_size=(4,), stride=(1,), dilation=(24,), groups=191)
      (bn_temp): MyBatchNorm1d(2292, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=2390, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (point_last_los): Linear(in_features=2781, out_features=17, bias=True)
  (point_last_mort): Linear(in_features=2781, out_features=17, bias=True)
)
2022-05-08 08:28:20,841 - INFO - Custom bins confusion matrix:
2022-05-08 08:28:20,841 - INFO - [[1173499  700406  151657   43718   16041    7104    3706    2184    3608
     1080]
 [ 396337  528281  192309   66674   25824   11899    6219    3551    5856
     1501]
 [ 132094  305594  176742   76142   31281   15150    8190    4699    8112
     1989]
 [  52783  169751  135159   72199   32091   16736    9365    5578    9880
     2488]
 [  26363  101836   95828   60074   30226   15958    9307    5835   11026
     2823]
 [  15014   66234   69064   47324   26304   14690    9001    5858   11395
     3171]
 [   9398   44888   51098   37796   22451   13141    8196    5458   11516
     3498]
 [   6023   31426   38864   29904   19046   11358    7495    5003   10941
     3681]
 [  14185   85223  111828   90493   65261   40481   27585   19851   47359
    19560]
 [   8516   46714   62848   54170   42865   28719   20197   14823   39351
    18625]]
2022-05-08 08:28:27,169 - INFO - Epoch: 0 | Train Loss: 86.8133
2022-05-08 08:36:56,122 - INFO - Custom bins confusion matrix:
2022-05-08 08:36:56,122 - INFO - [[308616 100128  25301   9360   3985   1544    547    323    125     13]
 [ 78355 104891  47739  19341   7583   3197   1322    541    249     24]
 [ 14087  49627  46786  28444  12641   5503   2455   1171    643     35]
 [  4348  18763  28491  25868  14767   7735   3680   1775   1332     28]
 [  1745   7861  14856  19622  14456   8106   4705   2073   2103     15]
 [   957   4353   8521  12705  12256   7952   5117   2599   2639     49]
 [   535   2315   4592   8411   9165   6966   5057   2987   3307    125]
 [   318   1536   2889   5599   6801   5791   4518   3090   3910    173]
 [   856   3688   6137  12130  15941  17954  16656  12908  23366   1560]
 [   562   1658   2594   4414   7526   9860  10199   9177  23960   1738]]
2022-05-08 08:38:24,217 - INFO - Epoch: 0 | Validation Loss: 54.9523
2022-05-08 10:02:43,324 - INFO - Custom bins confusion matrix:
2022-05-08 10:02:43,325 - INFO - [[1426044  505628  115356   35019   11684    4649    2070    1044    1351
      158]
 [ 380674  501471  232060   77972   25698    9962    4646    2423    3100
      445]
 [  81400  232881  237968  126203   43503   17806    8605    4470    6263
      894]
 [  24376   91738  147879  131705   55324   24353   12364    6803   10008
     1480]
 [  10780   41572   83341  101253   56024   26616   14622    8576   13943
     2549]
 [   5742   22770   49876   69497   48918   25893   15126    9468   17116
     3649]
 [   3228   12659   33161   47681   40194   23128   14217    9359   18972
     4841]
 [   2007    7665   22812   33254   31956   19854   12461    8745   19082
     5905]
 [   5075   17724   61044   78443   92101   68399   44658   32008   85177
    37197]
 [   2672    8460   34264   38404   51206   44462   31375   22670   65355
    37960]]
2022-05-08 10:02:49,215 - INFO - Epoch: 1 | Train Loss: 59.9714
2022-05-08 10:10:53,753 - INFO - Custom bins confusion matrix:
2022-05-08 10:10:53,754 - INFO - [[331788  88803  17533   7670   2542    931    354    169    152      0]
 [ 63979 117654  49170  21258   7114   2494    922    306    342      3]
 [  7878  42400  47877  40049  14028   5603   2125    792    613     27]
 [  2501  13428  21821  35599  18168   8353   3847   1728   1318     24]
 [  1053   5493   9205  22238  16887  10360   5189   2554   2489     74]
 [   682   2692   4679  12336  13786   9442   6118   3309   3923    181]
 [   288   1594   2553   6294   9228   8334   6125   3625   5177    242]
 [   254    969   1498   3774   6169   5824   5625   3875   6207    430]
 [   736   2294   3331   7315  11361  13749  15524  14105  37009   5772]
 [   444   1012   1317   2542   4117   7263   8878   8478  30812   6825]]
2022-05-08 10:10:55,249 - INFO - Epoch: 1 | Validation Loss: 42.1417
2022-05-08 11:35:16,403 - INFO - Custom bins confusion matrix:
2022-05-08 11:35:16,403 - INFO - [[1497086  470246   89663   30121    9130    3359    1571     756     948
      123]
 [ 351888  536679  231770   79975   22061    8105    3530    1795    2370
      278]
 [  62512  220641  240386  161246   42635   15812    7190    3714    5174
      683]
 [  17873   76223  125047  174559   60056   24118   11755    6183    8871
     1345]
 [   7739   32082   58605  127434   64000   29493   15367    8614   13657
     2285]
 [   4272   16836   30057   81478   56907   29602   16959   10422   17913
     3609]
 [   2555    9317   17116   52720   45100   27284   16262   10799   21233
     5054]
 [   1498    5430   10421   35863   34154   23138   14597    9889   22319
     6432]
 [   3788   12484   22853   88777   83720   75651   50990   36038   99968
    47557]
 [   2066    5889   10268   47314   40804   46231   34521   24777   75323
    49635]]
2022-05-08 11:35:22,523 - INFO - Epoch: 2 | Train Loss: 51.5170
2022-05-08 11:43:32,084 - INFO - Custom bins confusion matrix:
2022-05-08 11:43:32,084 - INFO - [[347967  78677  13014   5817   2739   1120    349    170     89      0]
 [ 61146 127773  45233  17487   6936   2785   1084    380    408     10]
 [  6411  42915  48356  38932  14245   6061   2608   1020    842      2]
 [  1953  12495  19497  36463  19223   9002   4300   1924   1883     47]
 [   794   5027   7703  19861  18867  10859   5903   3248   3188     92]
 [   532   2317   3728   9566  13687  11040   7299   3843   4929    207]
 [   262   1228   1931   4202   8162   9374   7064   4732   6127    378]
 [   230    661   1277   2469   5013   6051   5990   4819   7543    572]
 [   616   1759   2460   4675   8831  12357  15047  15398  42344   7709]
 [   271    791   1025   1719   3134   4558   6770   8615  35360   9445]]
2022-05-08 11:43:33,643 - INFO - Epoch: 2 | Validation Loss: 36.8141
2022-05-08 13:08:32,864 - INFO - Custom bins confusion matrix:
2022-05-08 13:08:32,865 - INFO - [[1540748  445421   78017   25407    7616    2923    1283     651     837
      100]
 [ 329977  559968  240857   73987   19341    7120    3225    1630    2119
      227]
 [  49997  210828  259223  169864   40256   14643    6672    3361    4578
      571]
 [  13831   65966  126669  189258   60148   23561   11043    5930    8424
     1200]
 [   6031   26500   54609  134061   67714   30690   15495    8799   13265
     2112]
 [   3419   13518   25995   81588   60991   31962   17874   10723   18614
     3371]
 [   2030    7547   14563   50361   46977   28987   17610   11593   22739
     5033]
 [   1283    4424    8810   33547   33957   24882   15294   10675   24159
     6710]
 [   3125    9734   18254   81676   78611   78346   53550   37648  108214
    52668]
 [   1648    4392    7838   44126   33983   45695   36631   25499   80273
    56743]]
2022-05-08 13:08:38,931 - INFO - Epoch: 3 | Train Loss: 46.6325
2022-05-08 13:16:45,506 - INFO - Custom bins confusion matrix:
2022-05-08 13:16:45,506 - INFO - [[344460  85706  11828   4309   2180    861    342    115    141      0]
 [ 47006 139363  49273  16684   6263   2728   1096    369    459      1]
 [  4276  39229  52528  41373  13608   5921   2432   1049    968      8]
 [  1420  11101  19681  37175  19883   9046   4406   2234   1787     54]
 [   686   4341   7114  19087  19212  11882   6182   3381   3536    121]
 [   379   1952   3477   9004  13457  11053   7321   4602   5672    231]
 [   203   1129   1681   4127   7623   8484   7086   5021   7695    411]
 [   172    637   1144   2342   4512   5548   5575   4710   9435    550]
 [   460   1574   2230   3965   7986  10620  13870  14049  48808   7634]
 [   175    689    914   1575   2547   4196   6128   7224  38915   9325]]
2022-05-08 13:16:47,106 - INFO - Epoch: 3 | Validation Loss: 33.5808
2022-05-08 13:16:47,108 - INFO - Experiment ended. Checkpoints stored =)
