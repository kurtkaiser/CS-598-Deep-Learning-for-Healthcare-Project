2022-05-08 09:27:21,357 - INFO - Config:
2022-05-08 09:27:21,358 - INFO - {
    "L2_regularisation": 0,
    "alpha": 100,
    "base_dir": "models/experiments/eICU/LoS/TPC",
    "batch_size": 32,
    "batch_size_test": 32,
    "batchnorm": "mybatchnorm",
    "dataset": "eICU",
    "diagnosis_size": 64,
    "disable_cuda": false,
    "exp_name": "TPC",
    "intermediate_reporting": false,
    "kernel_size": 4,
    "labs_only": false,
    "last_linear_size": 17,
    "learning_rate": 0.00226,
    "loss": "msle",
    "main_dropout_rate": 0.45,
    "mode": "train",
    "model_type": "tpc",
    "n_epochs": 8,
    "n_layers": 9,
    "name": "TPC",
    "no_diag": false,
    "no_exp": false,
    "no_labs": false,
    "no_mask": false,
    "no_skip_connections": false,
    "no_temp_kernels": 12,
    "percentage_data": 100.0,
    "point_size": 13,
    "point_sizes": [
        13,
        13,
        13,
        13,
        13,
        13,
        13,
        13,
        13
    ],
    "save_results_csv": false,
    "seed": 512982861,
    "share_weights": false,
    "shuffle_train": false,
    "sum_losses": true,
    "task": "LoS",
    "temp_dropout_rate": 0.05,
    "temp_kernels": [
        12,
        12,
        12,
        12,
        12,
        12,
        12,
        12,
        12
    ]
}
2022-05-08 09:27:48,234 - INFO - Experiment set up.
2022-05-08 09:27:49,390 - INFO - TempPointConv(
  (relu): ReLU()
  (sigmoid): Sigmoid()
  (hardtanh): Hardtanh(min_val=0.020833333333333332, max_val=100)
  (msle_loss): MSLELoss(
    (squared_error): MSELoss()
  )
  (mse_loss): MSELoss(
    (squared_error): MSELoss()
  )
  (bce_loss): BCELoss()
  (main_dropout): Dropout(p=0.45, inplace=False)
  (temp_dropout): Dropout(p=0.05, inplace=False)
  (empty_module): EmptyModule()
  (diagnosis_encoder): Linear(in_features=293, out_features=64, bias=True)
  (bn_diagnosis_encoder): MyBatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (bn_point_last_los): MyBatchNorm1d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (bn_point_last_mort): MyBatchNorm1d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (point_final_los): Linear(in_features=17, out_features=1, bias=True)
  (point_final_mort): Linear(in_features=17, out_features=1, bias=True)
  (layer_modules): ModuleDict(
    (0): ModuleDict(
      (temp): Conv1d(174, 1044, kernel_size=(4,), stride=(1,), groups=87)
      (bn_temp): MyBatchNorm1d(1044, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=241, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ModuleDict(
      (temp): Conv1d(1300, 1200, kernel_size=(4,), stride=(1,), dilation=(3,), groups=100)
      (bn_temp): MyBatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1298, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ModuleDict(
      (temp): Conv1d(1469, 1356, kernel_size=(4,), stride=(1,), dilation=(6,), groups=113)
      (bn_temp): MyBatchNorm1d(1356, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1454, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): ModuleDict(
      (temp): Conv1d(1638, 1512, kernel_size=(4,), stride=(1,), dilation=(9,), groups=126)
      (bn_temp): MyBatchNorm1d(1512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1610, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): ModuleDict(
      (temp): Conv1d(1807, 1668, kernel_size=(4,), stride=(1,), dilation=(12,), groups=139)
      (bn_temp): MyBatchNorm1d(1668, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1766, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): ModuleDict(
      (temp): Conv1d(1976, 1824, kernel_size=(4,), stride=(1,), dilation=(15,), groups=152)
      (bn_temp): MyBatchNorm1d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1922, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): ModuleDict(
      (temp): Conv1d(2145, 1980, kernel_size=(4,), stride=(1,), dilation=(18,), groups=165)
      (bn_temp): MyBatchNorm1d(1980, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=2078, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): ModuleDict(
      (temp): Conv1d(2314, 2136, kernel_size=(4,), stride=(1,), dilation=(21,), groups=178)
      (bn_temp): MyBatchNorm1d(2136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=2234, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): ModuleDict(
      (temp): Conv1d(2483, 2292, kernel_size=(4,), stride=(1,), dilation=(24,), groups=191)
      (bn_temp): MyBatchNorm1d(2292, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=2390, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (point_last_los): Linear(in_features=2781, out_features=17, bias=True)
  (point_last_mort): Linear(in_features=2781, out_features=17, bias=True)
)
2022-05-08 11:32:44,348 - INFO - Custom bins confusion matrix:
2022-05-08 11:32:44,349 - INFO - [[1185772  683746  142522   48613   19733    9286    4987    2679    4617
     1048]
 [ 401758  527387  173391   68689   30560   14962    8134    4656    7486
     1428]
 [ 133476  309484  159252   74241   35860   18684   10362    6245   10388
     2001]
 [  52710  168542  125124   69265   36368   19832   11641    7138   12839
     2571]
 [  25585   96243   89719   57790   33630   19548   11798    7691   14073
     3199]
 [  14064   59897   64096   46128   29066   17686   11382    7276   14720
     3740]
 [   8650   39066   46505   37008   24258   15733   10425    7003   14628
     4164]
 [   5263   26131   35056   29266   20404   13800    9220    6359   13956
     4286]
 [  11252   64983   97157   91023   68132   48773   34933   24832   59007
    21734]
 [   5534   33524   52245   54680   45024   34135   25390   18690   47719
    19887]]
2022-05-08 11:32:50,798 - INFO - Epoch: 0 | Train Loss: 83.9822
2022-05-08 11:46:34,149 - INFO - Custom bins confusion matrix:
2022-05-08 11:46:34,149 - INFO - [[287596 109860  32799  11951   4455   1692    775    385    426      3]
 [ 64452 112073  49537  21378   8818   3821   1479    763    920      1]
 [ 10009  48407  47393  28254  13382   6927   3610   1698   1693     19]
 [  2694  16816  27387  24111  15412   9095   5181   2970   3046     75]
 [  1123   6508  13818  17231  13285   9270   5988   3546   4618    155]
 [   752   3258   8060  11172   9971   8124   5918   3813   5794    286]
 [   417   1798   4527   7180   7177   6435   5397   3702   6291    536]
 [   214   1255   3013   4961   5030   4810   4507   3606   6538    691]
 [   744   3140   5937  10448  12779  14401  14377  13293  31408   4669]
 [   417   1169   2333   4461   6318   8204   8856   8981  27248   3701]]
2022-05-08 11:46:35,628 - INFO - Epoch: 0 | Validation Loss: 56.5804
2022-05-08 13:30:54,149 - INFO - Custom bins confusion matrix:
2022-05-08 13:30:54,149 - INFO - [[1451180  512834   88945   28462   10834    4684    2396    1332    2028
      308]
 [ 377088  584329  169460   58611   23785   11021    5584    3118    4731
      724]
 [  77547  301431  206646   88436   39201   19438   10311    5804    9581
     1598]
 [  22963  117222  155841   93449   48853   26069   14842    8817   15180
     2794]
 [  10244   49954   93757   75323   47918   28561   17401   11165   20626
     4327]
 [   5906   25982   55982   55316   39657   26155   17399   11718   23950
     5990]
 [   3511   15276   35659   39521   31291   22420   15828   11076   25321
     7537]
 [   2166    9260   23561   28681   24662   18347   13820   10204   24358
     8682]
 [   5455   20775   54064   75367   70848   59125   46471   36593  102581
    50547]
 [   2875   10741   27144   40269   41021   36237   30925   24906   76708
    46002]]
2022-05-08 13:31:00,143 - INFO - Epoch: 1 | Train Loss: 59.0989
2022-05-08 13:40:22,367 - INFO - Custom bins confusion matrix:
2022-05-08 13:40:22,367 - INFO - [[311496 105315  21278   7063   2605   1259    520    212    190      4]
 [ 44329 146729  45790  15555   6019   2655   1155    599    382     29]
 [  3966  49774  55888  28208  12567   5854   2656   1385   1088      6]
 [  1405  12203  28899  27064  16909   9782   5154   2556   2797     18]
 [   646   4720  11540  15962  15341  11160   6787   4164   5079    143]
 [   523   2538   5704   9084   9950   9420   7272   5042   7190    425]
 [   213   1425   3071   5419   6363   6725   5809   4912   8736    787]
 [   203    871   2066   3518   4214   4709   4371   3817   9899    957]
 [   584   2200   4245   6760   9217  10975  12319  12152  41037  11707]
 [   398   1005   1599   3156   4274   5054   5962   7122  30256  12862]]
2022-05-08 13:40:23,930 - INFO - Epoch: 1 | Validation Loss: 43.8882
2022-05-08 15:25:00,138 - INFO - Custom bins confusion matrix:
2022-05-08 15:25:00,139 - INFO - [[1527426  469331   69124   21065    8059    3546    1789    1024    1408
      231]
 [ 338842  644526  165424   50007   19501    8844    4662    2392    3745
      508]
 [  55886  305820  230481   88526   37335   17831    9361    5338    8209
     1206]
 [  16030  101561  168153  101966   51416   26754   14764    8707   14291
     2388]
 [   6951   39680   92718   82322   51816   30791   18375   11604   20949
     4070]
 [   4127   19476   51646   57269   42780   28746   19468   12653   25747
     6143]
 [   2656   11197   30959   39001   32780   24373   17585   12512   28158
     8219]
 [   1672    6628   19438   27293   24516   19895   15120   11347   28039
     9793]
 [   4067   14378   42693   65853   66462   58673   48328   39030  118413
    63929]
 [   2127    7466   20678   33057   35967   34337   30233   25733   85800
    61430]]
2022-05-08 15:25:06,056 - INFO - Epoch: 2 | Train Loss: 50.7781
2022-05-08 15:34:27,276 - INFO - Custom bins confusion matrix:
2022-05-08 15:34:27,276 - INFO - [[338114  87532  14527   5350   2266   1099    525    278    238     13]
 [ 49680 150339  40122  12473   4939   2413   1530    869    840     37]
 [  4392  55561  54791  23887  10793   5367   2971   1561   2052     17]
 [  1298  13786  30415  25553  14681   8549   5447   3216   3723    119]
 [   635   4393  11548  16423  14607   9841   6785   4443   6473    394]
 [   456   2174   5197   8339   9942   9430   6789   4870   9235    716]
 [   187   1134   2616   4411   5855   6400   6117   4611  11106   1023]
 [   149    736   1635   2904   3606   3911   4247   3923  11794   1720]
 [   522   1655   3017   5033   7098   8795   9675  10342  47639  17420]
 [   326    765    924   1614   2451   3756   4671   5238  32371  19572]]
2022-05-08 15:34:28,853 - INFO - Epoch: 2 | Validation Loss: 37.2555
2022-05-08 17:20:01,689 - INFO - Custom bins confusion matrix:
2022-05-08 17:20:01,690 - INFO - [[1577140  440538   56113   16715    6320    2702    1394     761    1156
      164]
 [ 312327  691119  157934   43826   16502    7485    3737    2009    3054
      458]
 [  43280  307404  247383   88826   35321   16356    8424    4668    7230
     1101]
 [  12211   90404  175446  108460   53500   27415   14672    8353   13306
     2263]
 [   5456   32739   91186   86315   55144   32384   19618   11672   20753
     4009]
 [   3070   15402   48137   58411   45250   30714   20436   13411   27056
     6168]
 [   1937    8648   27661   38628   33785   25795   18473   13492   30291
     8730]
 [   1209    5024   16876   26003   24836   20785   15753   11858   30444
    10953]
 [   2933   10849   36089   59815   63031   58455   49735   40677  127322
    72920]
 [   1543    5417   16365   27822   33086   32475   29729   25728   92272
    72391]]
2022-05-08 17:20:07,758 - INFO - Epoch: 3 | Train Loss: 45.2540
2022-05-08 17:29:34,061 - INFO - Custom bins confusion matrix:
2022-05-08 17:29:34,061 - INFO - [[351580  83363   9523   3173   1148    577    295    149    126      8]
 [ 43061 173739  31358   8642   3161   1548    768    475    476     14]
 [  3103  66308  55122  20500   8097   3953   2015    986   1300      8]
 [  1017  15327  33017  25765  14846   7928   3921   2191   2752     23]
 [   431   4974  11698  16266  15305  11335   6987   3787   4643    116]
 [   352   2314   5343   8076   9653  10030   7855   5182   7889    454]
 [   143   1242   2645   4152   5873   6358   6607   5280  10482    678]
 [   152    840   1645   2510   3691   4232   4316   4171  11769   1299]
 [   389   1921   3380   5713   7935   9210  10049   9564  42507  20528]
 [   270    919   1189   2074   3653   4973   4956   4980  25469  23205]]
2022-05-08 17:29:35,622 - INFO - Epoch: 3 | Validation Loss: 32.4853
2022-05-08 19:15:20,302 - INFO - Custom bins confusion matrix:
2022-05-08 19:15:20,302 - INFO - [[1609331  420495   48246   14312    5329    2463    1153     634     911
      129]
 [ 293382  721482  154370   39981   14707    6443    3353    1793    2566
      374]
 [  35260  305651  261873   88889   34029   15242    7427    4322    6360
      940]
 [   9762   81998  182868  113073   54819   26848   14209    8073   12460
     1920]
 [   4377   27707   89892   90022   57533   33672   19676   12024   20678
     3695]
 [   2626   12655   45091   59243   47111   32523   21380   14029   27479
     5918]
 [   1601    6894   25235   38600   34431   26979   19560   14139   31367
     8634]
 [    889    4021   15228   25090   25053   21129   16585   12633   32075
    11038]
 [   2275    8705   31618   55646   61051   57611   50074   41847  133731
    79268]
 [   1196    4389   14288   25032   30581   30517   28516   25556   95036
    81717]]
2022-05-08 19:15:26,512 - INFO - Epoch: 4 | Train Loss: 41.6097
2022-05-08 19:24:58,584 - INFO - Custom bins confusion matrix:
2022-05-08 19:24:58,585 - INFO - [[354136  81112   9910   2796   1029    488    220    117    129      5]
 [ 40489 174916  33510   8269   3095   1476    693    367    414     13]
 [  2287  62209  61031  20616   7643   3594   1858    948   1178     28]
 [   746  12558  35658  27873  13970   7060   3915   2225   2748     34]
 [   406   3733  12496  17937  15268  10112   6365   3597   5424    204]
 [   199   1749   5461   8795  10374   9536   6953   4709   8710    662]
 [   120    914   2550   4451   6063   6278   6069   4721  11143   1151]
 [   119    580   1496   2633   3522   4054   4250   3808  12140   2023]
 [   286   1311   2886   4535   6168   7306   8887  10311  48408  21098]
 [   166    626    991   1431   2131   2846   3423   4037  32216  23821]]
2022-05-08 19:25:00,181 - INFO - Epoch: 4 | Validation Loss: 29.5868
2022-05-08 21:11:47,641 - INFO - Custom bins confusion matrix:
2022-05-08 21:11:47,641 - INFO - [[1634831  405374   41662   12222    4470    1968    1015     542     798
      121]
 [ 278973  747006  150228   36205   13264    5765    2871    1558    2229
      352]
 [  29309  301715  275033   89505   32771   14383    6935    3867    5639
      836]
 [   8105   72719  187228  119276   56530   27078   13901    7705   11646
     1842]
 [   3648   23402   88021   93653   60553   34563   20036   11985   19982
     3433]
 [   2043   10643   43065   59946   48711   33413   21880   14582   27945
     5827]
 [   1231    5938   23281   37932   35370   27824   20219   14518   32448
     8679]
 [    623    3313   14004   24713   24852   21632   17011   12928   33216
    11449]
 [   1806    7279   28415   52284   59301   57420   50226   42355  139252
    83488]
 [    912    3626   12518   22392   29158   29223   28207   25311   96988
    88493]]
2022-05-08 21:11:53,516 - INFO - Epoch: 5 | Train Loss: 38.6985
2022-05-08 21:21:25,421 - INFO - Custom bins confusion matrix:
2022-05-08 21:21:25,422 - INFO - [[356547  81382   7922   2451    870    374    215     97     70     14]
 [ 32939 184119  32997   7876   2840   1259    650    284    267     11]
 [  1902  59474  61579  23434   8368   3210   1665    879    870     11]
 [   638  11531  32209  29026  16722   7958   4162   2094   2421     26]
 [   397   3407  10958  16727  16113  11615   6979   4121   5039    186]
 [   231   1714   4820   8099   9772   9662   7904   5497   8940    509]
 [   141    966   2247   4120   5472   6346   5830   5059  12360    919]
 [   104    645   1321   2600   3228   3917   3962   3766  13090   1992]
 [   273   1775   3163   4596   6398   6998   7577   9036  46963  24417]
 [   154    854   1480   1744   2397   3049   3432   3682  27835  27061]]
2022-05-08 21:21:26,938 - INFO - Epoch: 5 | Validation Loss: 27.5083
2022-05-08 23:08:31,081 - INFO - Custom bins confusion matrix:
2022-05-08 23:08:31,081 - INFO - [[1653608  393607   37170   10899    3925    1667     853     474     694
      106]
 [ 265040  769730  146207   34080   12134    5198    2508    1263    1979
      312]
 [  24622  299183  284403   90057   32156   13638    6617    3521    5040
      756]
 [   6691   66613  190536  123664   57530   27239   13578    7352   11163
     1664]
 [   3058   20394   87214   95902   62119   35587   20564   12026   19258
     3154]
 [   1798    9356   41077   60398   50453   34848   22386   14586   27554
     5599]
 [   1073    5070   22516   37651   36308   28394   20752   14612   32608
     8456]
 [    572    2931   13204   24484   25135   21692   17166   13389   33841
    11327]
 [   1357    6372   26027   50398   58111   57195   50247   43002  142117
    87000]
 [    647    2910   11452   20371   27242   27463   27177   24851   98671
    96044]]
2022-05-08 23:08:37,131 - INFO - Epoch: 6 | Train Loss: 36.3530
2022-05-08 23:18:14,259 - INFO - Custom bins confusion matrix:
2022-05-08 23:18:14,260 - INFO - [[365223  74172   6982   2128    788    270    193     91     88      7]
 [ 34544 185767  30912   7329   2566   1151    457    275    232      9]
 [  2118  60624  63114  21629   7805   3308   1457    684    650      3]
 [   718  11005  34349  30378  15601   7104   3745   2019   1813     55]
 [   449   3338  11299  18154  17073  11067   6146   3469   4397    150]
 [   174   1649   5059   8380  10871  10372   7680   4633   7933    397]
 [   124    872   2182   4137   6107   6857   6487   5202  10561    931]
 [    99    510   1299   2460   3698   4331   4433   4237  11982   1576]
 [   273   1646   3203   4970   6623   7825   9212   9820  48482  19142]
 [   161    983   1477   1958   2707   3092   3771   4437  30249  22853]]
2022-05-08 23:18:15,782 - INFO - Epoch: 6 | Validation Loss: 25.9577
2022-05-09 01:05:54,201 - INFO - Custom bins confusion matrix:
2022-05-09 01:05:54,202 - INFO - [[1667030  385259   34279    9644    3451    1494     749     402     600
       95]
 [ 254747  787855  142564   32091   11160    4630    2246    1207    1698
      253]
 [  22494  298021  291893   89063   30939   12890    6089    3273    4609
      722]
 [   5784   62413  192850  127239   58004   27069   13303    7282   10528
     1558]
 [   2461   18706   85667   97587   63536   36453   20816   12020   18908
     3122]
 [   1419    8282   39948   60810   50844   35405   23126   15060   27872
     5289]
 [    792    4621   21236   37608   36772   28718   21231   15079   33025
     8358]
 [    491    2482   12295   23955   25262   22404   17689   13576   34237
    11350]
 [   1074    5658   24592   48458   57572   57434   50921   43341  144463
    88313]
 [    507    2539   10282   18493   25586   26257   26420   24789   99375
   102580]]
2022-05-09 01:06:00,144 - INFO - Epoch: 7 | Train Loss: 34.6095
2022-05-09 01:15:32,675 - INFO - Custom bins confusion matrix:
2022-05-09 01:15:32,676 - INFO - [[366203  72382   7343   2330    861    372    183    132    125     11]
 [ 33839 186382  30909   7042   2520   1135    623    352    422     18]
 [  1819  56806  67068  21427   7683   3248   1500    827    993     21]
 [   541   8411  33217  32972  16394   7404   3566   1922   2302     58]
 [   295   2257   9076  18087  19350  11994   6301   3364   4579    239]
 [   158   1040   3671   8056  11393  11398   8217   5039   7627    549]
 [   101    599   1614   3519   6023   7370   7246   5744  10316    928]
 [    51    364    966   2056   3309   4418   5041   4627  12317   1476]
 [   189    857   2256   4160   5827   7527   8941  10134  51626  19679]
 [    80    385    989   1400   2080   2668   3330   3710  31618  25428]]
2022-05-09 01:15:34,233 - INFO - Epoch: 7 | Validation Loss: 24.5970
2022-05-09 01:15:34,236 - INFO - Experiment ended. Checkpoints stored =)
