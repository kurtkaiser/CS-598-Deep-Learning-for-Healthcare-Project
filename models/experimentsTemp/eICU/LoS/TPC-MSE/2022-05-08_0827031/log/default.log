2022-05-08 08:27:03,721 - INFO - Config:
2022-05-08 08:27:03,721 - INFO - {
    "L2_regularisation": 0,
    "alpha": 100,
    "base_dir": "models/experiments/eICU/LoS/TPC",
    "batch_size": 32,
    "batch_size_test": 32,
    "batchnorm": "mybatchnorm",
    "dataset": "eICU",
    "diagnosis_size": 64,
    "disable_cuda": false,
    "exp_name": "TPC",
    "intermediate_reporting": false,
    "kernel_size": 4,
    "labs_only": false,
    "last_linear_size": 17,
    "learning_rate": 0.00226,
    "loss": "mse",
    "main_dropout_rate": 0.45,
    "mode": "train",
    "model_type": "tpc",
    "n_epochs": 3,
    "n_layers": 9,
    "name": "TPC",
    "no_diag": false,
    "no_exp": false,
    "no_labs": false,
    "no_mask": false,
    "no_skip_connections": false,
    "no_temp_kernels": 12,
    "percentage_data": 100.0,
    "point_size": 13,
    "point_sizes": [
        13,
        13,
        13,
        13,
        13,
        13,
        13,
        13,
        13
    ],
    "save_results_csv": false,
    "seed": 3998441340,
    "share_weights": false,
    "shuffle_train": false,
    "sum_losses": true,
    "task": "LoS",
    "temp_dropout_rate": 0.05,
    "temp_kernels": [
        12,
        12,
        12,
        12,
        12,
        12,
        12,
        12,
        12
    ]
}
2022-05-08 08:27:07,304 - INFO - Experiment set up.
2022-05-08 08:27:07,336 - INFO - TempPointConv(
  (relu): ReLU()
  (sigmoid): Sigmoid()
  (hardtanh): Hardtanh(min_val=0.020833333333333332, max_val=100)
  (msle_loss): MSLELoss(
    (squared_error): MSELoss()
  )
  (mse_loss): MSELoss(
    (squared_error): MSELoss()
  )
  (bce_loss): BCELoss()
  (main_dropout): Dropout(p=0.45, inplace=False)
  (temp_dropout): Dropout(p=0.05, inplace=False)
  (empty_module): EmptyModule()
  (diagnosis_encoder): Linear(in_features=293, out_features=64, bias=True)
  (bn_diagnosis_encoder): MyBatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (bn_point_last_los): MyBatchNorm1d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (bn_point_last_mort): MyBatchNorm1d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (point_final_los): Linear(in_features=17, out_features=1, bias=True)
  (point_final_mort): Linear(in_features=17, out_features=1, bias=True)
  (layer_modules): ModuleDict(
    (0): ModuleDict(
      (temp): Conv1d(174, 1044, kernel_size=(4,), stride=(1,), groups=87)
      (bn_temp): MyBatchNorm1d(1044, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=241, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ModuleDict(
      (temp): Conv1d(1300, 1200, kernel_size=(4,), stride=(1,), dilation=(3,), groups=100)
      (bn_temp): MyBatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1298, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ModuleDict(
      (temp): Conv1d(1469, 1356, kernel_size=(4,), stride=(1,), dilation=(6,), groups=113)
      (bn_temp): MyBatchNorm1d(1356, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1454, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): ModuleDict(
      (temp): Conv1d(1638, 1512, kernel_size=(4,), stride=(1,), dilation=(9,), groups=126)
      (bn_temp): MyBatchNorm1d(1512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1610, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): ModuleDict(
      (temp): Conv1d(1807, 1668, kernel_size=(4,), stride=(1,), dilation=(12,), groups=139)
      (bn_temp): MyBatchNorm1d(1668, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1766, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): ModuleDict(
      (temp): Conv1d(1976, 1824, kernel_size=(4,), stride=(1,), dilation=(15,), groups=152)
      (bn_temp): MyBatchNorm1d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1922, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): ModuleDict(
      (temp): Conv1d(2145, 1980, kernel_size=(4,), stride=(1,), dilation=(18,), groups=165)
      (bn_temp): MyBatchNorm1d(1980, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=2078, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): ModuleDict(
      (temp): Conv1d(2314, 2136, kernel_size=(4,), stride=(1,), dilation=(21,), groups=178)
      (bn_temp): MyBatchNorm1d(2136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=2234, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): ModuleDict(
      (temp): Conv1d(2483, 2292, kernel_size=(4,), stride=(1,), dilation=(24,), groups=191)
      (bn_temp): MyBatchNorm1d(2292, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=2390, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (point_last_los): Linear(in_features=2781, out_features=17, bias=True)
  (point_last_mort): Linear(in_features=2781, out_features=17, bias=True)
)
2022-05-08 10:52:58,777 - INFO - Custom bins confusion matrix:
2022-05-08 10:52:58,777 - INFO - [[115394 875848 654019 243847 106294  50673  25271  13163  17023   1471]
 [ 41386 416736 392489 182201  93350  49558  26647  14658  19712   1714]
 [ 16130 205432 231197 129214  74654  42701  24666  14070  20162   1767]
 [  6726 110145 144272  93719  59837  36074  21525  12917  19011   1804]
 [  3032  63967  95547  69200  47263  30414  19164  11422  17652   1615]
 [  1434  39810  65155  52698  38440  25534  16602  10341  16337   1704]
 [   799  25892  46033  40991  31492  21698  14410   9278  15121   1726]
 [   387  17111  32778  31731  26168  18894  12838   8097  14135   1602]
 [   993  39941  86327  93870  85214  66622  47462  32633  60761   8003]
 [   738  19418  43863  52420  52521  45031  35542  25633  53273   8389]]
2022-05-08 10:53:05,655 - INFO - Epoch: 0 | Train Loss: 2047.1699
2022-05-08 11:08:48,768 - INFO - Custom bins confusion matrix:
2022-05-08 11:08:48,768 - INFO - [[ 22715 137729 157031  68395  35187  16863   7185   3307   1507     23]
 [  5176  58191  87995  49430  29935  17539   8801   4340   1824     11]
 [   988  24181  48513  32900  22948  15178   9511   4828   2345      0]
 [   181  10069  28023  21424  17812  12777   8890   5162   2449      0]
 [    31   4179  15736  14855  14161  10989   7942   4920   2729      0]
 [     0   1869  10177  10413  10582   9773   6780   4497   3057      0]
 [    23    766   6003   7639   7526   8059   5897   4202   3345      0]
 [    12    422   3764   5273   5806   6339   5744   4067   3198      0]
 [     7    690   5580   9960  15417  21279  23798  18871  15557     37]
 [     0     76   1446   4396   6510  10594  16176  14790  17700      0]]
2022-05-08 11:08:50,410 - INFO - Epoch: 0 | Validation Loss: 3327.9994
2022-05-08 13:12:31,822 - INFO - Custom bins confusion matrix:
2022-05-08 13:12:31,822 - INFO - [[528501 677619 440416 214529 108476  60705  30962  17654  22841   1300]
 [202052 352192 279244 162358  95894  59905  35138  21156  28858   1654]
 [ 77192 178870 168383 114555  77655  53908  33899  21817  31713   2001]
 [ 29210  93027 104745  82187  61712  47087  31905  21213  32701   2243]
 [ 12125  48297  65743  59241  48704  40435  28932  20308  33005   2486]
 [  5593  26030  40304  41955  39168  34256  25866  19125  33121   2637]
 [  2809  14678  24711  29103  30622  28896  23069  17712  32914   2926]
 [  1394   8170  15333  19722  23708  24153  20396  15919  31921   3025]
 [  2203  14452  29348  42016  60017  74719  72906  63157 146402  16606]
 [   690   4935  10948  16581  26495  38994  45283  44788 127154  20960]]
2022-05-08 13:12:38,219 - INFO - Epoch: 1 | Train Loss: 1736.8454
2022-05-08 13:23:49,833 - INFO - Custom bins confusion matrix:
2022-05-08 13:23:49,833 - INFO - [[ 77640 156937 103801  50800  24109  17125   7442   4330   7462    296]
 [ 20465  76909  67487  39483  20524  16060   7548   5088   9207    471]
 [  4092  31860  41982  28670  17530  13797   7142   4771  10804    744]
 [   698  12079  23986  20325  14077  11830   6606   4554  11569   1063]
 [   133   4165  11679  14470  11045  10768   5795   4552  11648   1287]
 [    55   1520   5955   9098   8811   9122   5427   4441  11045   1674]
 [    42    662   2809   5191   5878   7112   4779   3997  11097   1893]
 [     6    359   1494   3122   4031   5398   3918   3289  10929   2079]
 [    51    590   2298   4486   7087  13896  11018  11927  48174  11669]
 [    14    267    789   1360   2293   5751   4717   6415  35164  14918]]
2022-05-08 13:23:51,460 - INFO - Epoch: 1 | Validation Loss: 3089.9122
2022-05-08 15:33:20,338 - INFO - Custom bins confusion matrix:
2022-05-08 15:33:20,339 - INFO - [[840198 559591 318258 168103  88871  51023  34680  18872  22288   1119]
 [351339 327478 218137 130518  76322  48854  35290  21739  27343   1431]
 [141148 183313 142255  96849  62574  43353  34281  22914  31477   1829]
 [ 54440 100153  93063  72902  52732  39107  32881  23686  34847   2219]
 [ 21625  52730  58697  52915  42418  34560  30755  23644  39314   2618]
 [  9101  27106  35349  35792  33202  29854  28508  23201  42681   3261]
 [  4258  14153  20541  23105  24314  24202  25565  21898  45612   3792]
 [  1877   7323  11813  14968  16735  18888  21560  19841  46314   4422]
 [  3395  11750  20692  27949  33957  42989  62216  69106 218015  31757]
 [  1105   3896   6844   9433  12383  17626  30075  37004 173416  45046]]
2022-05-08 15:33:26,927 - INFO - Epoch: 2 | Train Loss: 1549.4920
2022-05-08 15:44:58,509 - INFO - Custom bins confusion matrix:
2022-05-08 15:44:58,510 - INFO - [[150719 150520  78710  33964  15409   7760   5007   3032   4334    487]
 [ 52975  87794  55846  29172  14168   8068   5349   3650   5517    703]
 [ 15831  46662  39016  23744  12414   7583   5450   3592   6193    907]
 [  3534  22286  26587  19229  10674   7457   5103   3995   6714   1208]
 [   661   8784  16064  14803   9810   7029   5271   4402   7295   1423]
 [   182   3034   8985  10269   8542   6413   5619   4800   7524   1780]
 [    95   1161   3912   6301   6222   5458   5302   4628   8381   2000]
 [     4    561   2084   3472   3877   4456   4849   4453   8603   2266]
 [   125    788   2613   5210   7674   9408  12210  14624  44192  14352]
 [    58    346   1026   1659   2635   3795   5404   6476  31165  19124]]
2022-05-08 15:45:00,352 - INFO - Epoch: 2 | Validation Loss: 2967.0325
2022-05-08 15:45:00,354 - INFO - Experiment ended. Checkpoints stored =)
